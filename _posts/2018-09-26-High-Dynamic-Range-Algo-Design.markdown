---
layout:     post
title:      "High Dynamic Range Algorithm Design"
subtitle:   " \"ISP Design Part I\""
date:       2018-09-26 12:00:00
author:     "McCreeNing"
header-img: "img/HDR.jpeg"
tags:
    - 算法
    - 编程
    - 科普
---

# 前言

  HighDynamicRange顾名思义，叫做高动态范围技术，是一种用一张图片在低动态显示器上可以同时显示极亮极暗处细节的一种图像处理技术。

  本文主要是跟随着本人github开源项目[ISP-DESIGN](https://github.com/NingYi0401/ISP-DESIGN)中HDR模块同步介绍，作为工程的说明文档和简单补充。

  初步估计本文会包含：

  - HDR技术的基本概念
  - 实现过程中遇到的难点和工程化技巧
  - 各模块实现功能区分
  - 最终算法DEMO的相关参数
  - 后续可能的改进方向以及硬件化实现讨论

本文将跟随项目实际进度持续更新，欢迎大家提出宝贵意见，本人coding功力和硬件开销的了解不够深入，因此希望跟大家一起进步。

本文仅仅作为简单的补充说明，因此全篇不会有多余引用和其他参照，仅仅凭借个人项目经验进行总结，因此如有疏漏请及时与我沟通。

# HDR基本概念

生活中我们用眼睛看到的场景，偶尔会出现从暗处走向光明觉得刺眼无法适应，需要花一点时间才能正视外面的天空，对于外面这种太阳高照的场景如果我们用七大物理常量之一的光强度坎德拉来形容，就是在触目可及的场景中又有光强很高很高的太阳，又有很暗的树荫，甚至于对于坎德拉而言这二者的光强完全不是一个普通的数量级。

而目前我们用来显示图像的显示器们，比如电脑屏幕电视屏幕或者印刷品上面的图片等等，如果大家好奇可以打开windows的画图功能，通过调整一下画板的RGB值就可以知道，我们所最常用的图片显示装置都是基于8bit，也就是最大值只有256而已。在我们没法使用小数的情况下，我们需要使用0-255这256个灰阶来表示全部的亮度信息【无论是亮度还是照度，他们在实际场景中都是远远高于8bit/256个取值范围的】，因此我们需要使用一种技术能够把太阳+树荫这种高动态范围的亮度场景在同一个低位宽显示装置上显示出来，并且可以让观者能够不影响观感的清晰看到亮处以及暗处的全部细节。使用普通充满限制的灰阶来显示大量的高动态范围的数据，这就是我们HDR算法所要实现的功能。

# HDR模块功能区分

---
        2018年10月10日15:16:45 update
---

因为要准备晚上给组员们的分享会，要教教他们HDR算法里面到底做了什么东西，所以赶紧趁着这个机会把这篇博文填点坑出来。晚上讲东西就按照这个讲了。

### 综述

为了能够同时拥有高亮和阴暗场景两部分的细节主体，因此仅仅通过单一sensor一重曝光很难得到让我们满意的图像（不然要我们HDR干嘛），因此我们通过使用同一sensor进行多重曝光，通过控制曝光行曝光增益等曝光相关参数，得到原图覆盖部分亮度区域细节的多张不同曝光原图。而我们也正是基于这几张图进行我们HDR算法的展开运算，将每个图中所需要的清晰细节进行分割集合成同一张图进行最终的输出。

基于HDR的基本概念，我们需要有两部分主体模块，首先是用来将多张拥有差异图像细节的原图根据某种规则合成为同一张图。为了让两张不同曝光（理论上是增益不同的两张图）进行同一化合成，因此我们得到的图位宽将大大高于原图（正相关于几张图的曝光比）。这部分合成模块我们称之为Combine。

为了让这张HDR图能够在LDR显示器256的的范围内得以正确显示并保留HDR的效果，因为我们还需要一次压缩将高动态的数据压缩成8bit的数据量。然而对于一张有极亮有极暗的图像，按照韦伯定律的习惯性总结，人们在意的往往都是暗处的细节，毕竟亮了之后都是白白白白你能看到啥，因此我们无法简单的进行线性压缩，我们要在保留高亮细节区分的程度之外要尽可能的提亮暗处并保留全部细节，因此我们同样需要找到一个映射关系作为我们进行压缩的规则，这部分功能模块我们称之为ToneMapping。

为了把我们的算法做成模块化的算法，因此我们希望它拥有足够的鲁棒性跟适配性，有充分的后续升级可能，因此我们把这几部分代码均抽象成单一固定接口，仅仅传入固定的数据流已经需要初始化的相关参数，抽象成相关接口方便硬件化模块化完成算法的移植工作。

而对于芯片而言，为了使得tonemapping模块可以复用在多种比特位宽的输入中，因此我们定义了一个接口层模块：normalize。其主要的效果是将combine的输出数据不达到16bit的时候根据当前bit位数统一固定位宽到16bit交由tonemapping进行处理。而tonemapping贼固定的根据输入位宽进行HDR-LDR的压缩工作。

其他剩余模块主要功能是在不同的数域进行对亮度的处理，主要为了提升暗处细节的亮度，对高亮部分占用过多的情况进行压缩。面对可能存在的饱和度下降以及可能出现的比特位宽溢出情况进行我们所需要的限制和压缩。


# HDR分模块详解

首先该算法是ISP芯片内置算法，因此及其追求硬件友好型，代码设计风格上也十分适配硬件设计语言，为了方便硬件实现，因此很多参数、接口、内存空间管理均以方便硬件实现为准，不过后续在我重构当前算法时，会尽量考虑软件性能开销。

## 主函数

作为一个通用的模块，因此需要满足硬件流水线上对于每一个模块task化的要求，所有函数的参数以及相关初始化需要进行分割，为了方便后续测试人员调试具体产品，因此也希望我们各对象接口的可调性足够强，因此会抽象出很多函数内函数外参数作为调试专用。

其中主函数便提供了由命令行传参到main函数argv[]的功能，内部通过strcmp对应传参得到具体本次编译执行过程中需要使用哪部分的模块。其中也包括了待处理图像的长宽地址等信息。

提供一个单一接口作为HDR的同一接口，主函数主要包括：
- 从命令行传参进函数主题并进行存储
- 读取外部一个参数.txt文件作为函数内部寄存器初始化参数默认值
- 初始化全局结构体作为外界配置时候的初始化寄存器参数
- 加载HDR输入图像数据到一个首地址int*的内存中
- 执行HDR算法的通用接口
- 储存HDR算法输出到本地（实际硬件是通过pipeline将数据流传递给下一个模块）

## 初始化函数

---

2018年12月7日14点57分更新

---


HDR算法的初始化主要包括两部分：1.从执行可执行文件同时读取命令行传参比如输入图像绝对路径/图像尺寸/各模块选择器使能开关，以及通过参数文本文件读入的函数内部需要使用的算法参数初始值。2.一些从外界读取比较复杂，以及部分用于firmware使用的多帧运算可变参数，在内部算法开始时进行一次算法内部赋值初始化。

前者在硬件实现上一般是有pipeline前序模块传递相关信息，比如：pixel order/bit witdh/image相关参数信息等，以及一些硬件寄存器RW/RO可以供调试人员使用。而后者一般局限于固件寄存器以及部分封装内部接口不需要暴露给外界使用。

原则上，设计算法过程中为了保证全局各模块参数传递以及多帧固件流程，采用多个全局结构体进行参数存储和传递。我们需要注意对全局结构体声明/初始化/以及范围检查等操作，保证各模块使用的数据有效且可靠。


## 顶层函数

---

2018年12月26日15点14分更新

---

顶层函数主要为了提供给执行HDR算法的通用接口，同时为了视频模拟进行了对重复帧输入输出的模拟操作。在HDR算法结束后，针对RAW12的输出进行了一次CIP插值将RAW数据转化为RGB8bit的数据输出方便进行图像效果比对。

## HDR算法处理函数

HDR算法处理函数作为HDR各模块的接口封装层，主要是调用了HDR算法内部的各个具体模块，并统一为同一个接口供顶层函数调用，其中需要的输入主要是在初始化函数中进行初始化的全局参数用来给函数内部使用，以及需要处理的数据输入本算法使用三张不同曝光值的图像数据作为图像输入，以及其他const类型参数。

HDR算法处理函数特异化操作主要在于为了支持硬件设计，做了一些硬件友好的优化：

- 重复的开辟了很多内存空间，为了区分各子模块的输入输出，在硬件实现过程中不涉及到固定地址的内存读取写入操作，因此通过不一样的变量名加以定义可以使得代码阅读性更好。

- 提供了各个子模块的使能开关，根据全局开关参数判断当前HDR算法流程应该bypass掉哪部分，根据不同的使能开关组合，HDR算法提供了WDR/两帧HDR/三帧HDR等数据通路，并提供了多个效果模块GAMMA/饱和度处理等。

---

## HDR算法子模块

### 解压缩模块

正常HDR算法的输入是由HDRsensor时分复用提供两张到三张不同曝光的同样大小同一场景原图经过MIPI特殊协议传输并在HDR算法内部进行combine过程输出高动态图像进行ToneMapping进行压缩。而市场上存在一些sensor本身在sensor内部就有combine模块，在传输到ISP之前便经过自己sensor内部的combine模块生成一个高动态范围的图像，而为了满足图像输出格式要求，以及减小图像位宽的需求，sensor内部一般进行了一次非线性压缩再传输。

因此对于这类sensor，我们需要在获得数据的最开始进行一次数据解压缩获得原始高动态图像后直接送到tonemapping入口处进行处理。

算法整体思路是根据sensor自带压缩模块的压缩公式进行方向推导，通过一个跟节点相关的矩阵进行函数反变换。

### 场景检测模块



















# HDR当前存在的问题

- 为什么combine模块要放到log域做，除了计算上可以把乘法转化为加法优化处理速度之外，是否有提起的作用：此问题我觉得已经解决，应该是为了节省位宽并符合人眼感官要求。

- Gamma模块添加两个是否多余：这个问题我觉得也解决了，并不多余，gamma模块有两个作用，一个是2.2gamma用来反映射CRT屏幕的响应曲线，为了找到真实的颜色，而我们的gamma是用来局部提亮为了满足视觉的真实感受需求。

# HDR后续的设想

- log域可能是因为进行压缩之后相当于一次成功的gamma操作，那么使用linear域进行该操作是否可行？

- HDR采用的多帧图像理论上进行合成应该能起到原图去噪的效果，因此可否通过combine进行合成并保持全部细节交给tonemapping进行WDR类似的操作即有HDR的效果又能降噪？可以直接使用HDR两张图资源优势也比较大。

- 现在采用简单的限制对比度的直方图均衡方式是否足够满足需求？实际进行的操作与tonemapping本质并无相关，只是做了简单的移位，是否有可能后续修改？
